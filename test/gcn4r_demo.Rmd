---
title: "GCN4R_demo"
author: "Joshua Levy"
date: "4/28/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(gcn4r)
```

# Install package
```{r}
# install.packages("reticulate")
# devtools::install_github("jlevy44/gcn4r")
# conda_create("gcn4r")
# conda_install("gcn4r", "gcn4r",pip=T)
# use_condaenv("gcn4r")
```


# Import Library, link anaconda to R studio
```{r}
# http://moreno.ss.uci.edu/data.html
reticulate:::conda_list(conda = "auto")
reticulate::use_condaenv(condaenv = "gcn4r", conda = "/anaconda2/bin/conda")
reticulate:::use_python("/anaconda2/envs/gcn4r/bin/python")
GCN4R<-import_gcn4r()
```


# Load data
Comment out below to download and save Lazega Network.
```{r}
# devtools::install_github("zalmquist/networkdata")
# library(networkdata)
# data("lazega")
# saveRDS(asIgraph(lazega$FRIENDSHIP),"netdata.rds")
net<-readRDS("netdata.rds")
```

```{r}
# alternative data
physician.files<-c("../gcn4r/data/A_physician.csv","../gcn4r/data/X_physician.csv")
lawyer.files<-c("A_lawyer.csv","X_lawyer.csv")
# load lawyer data from csv
# net.list<-generate.net.list(lawyer.files[1],lawyer.files[2]) 
# load lawyer data from igraph
net.list<-igraph2net.list(net)
# create factor variables
net.list$X[,c("na","vertex.names")]<-NULL
for (cat.var in c("gender","law_school","office","practice","status")){
  net.list$X[,cat.var]<-as.factor(net.list$X[,cat.var])
}
```

# Create design matrix to expand factors, update net.list
```{r}
net.list$X<-model.matrix(~.,data=net.list$X)[,-1]
head(net.list$X)
```

# Visualize data

```{r}
visualize.net2(net.list,covar = "office2")
```

# Load parameters

```{r}
parameters<-generate_default_parameters()
```

# Update parameters

```{r}
new.parameters<-list(encoder_base="GATConv",
                     K=3L,
                     epoch_cluster=150L,
                     n_layers=1L,
                     use_mincut=T,
                     ae_type="ARGA",
                     custom_dataset="none",
                     learning_rate=1e-2,
                     lambda_kl=0.,
                     lambda_adv=1e-3,
                     lambda_cluster=12.,
                     lambda_recon=3.,
                     model_save_loc="cluster.model.pkl")
parameters<-update.parameters(parameters,new.parameters)
```


# Fit cluster, embedding, classification, generation, or link prediction model
```{r}
cluster.model<-cluster.model.fit(parameters, net.list,verbose=F)
```

# Plot Objective Convergence
```{r}
plot.diagnostics(cluster.model)
```

# Summarize Results
```{r}
results<-extract.results(cluster.model)
graphs<-extract.graphs(cluster.model)
cl<-extract.clusters(cluster.model)
summary(cluster.model,additional.info=F)
```

# Visualize Results
```{r}
plot(cluster.model)

# Select predicted and save image
tiff(file = "test.tiff", width = 2000, height = 2000, units = "px", res = 600)
plot(cluster.model,plots=c(2))
dev.off()

# plot latent positions
plot(cluster.model,latent=T,plots=c(2))
```


# Interpret
# Attention between Two Individuals 
```{r}
attention.matrices<-visualize.attention(cluster.model,weight.scaling.factor = 4)

# With latent embeddings
attention.matrices<-visualize.attention(cluster.model,weight.scaling.factor = 4, latent=T)
```

# Important Samples and Features per Cluster Assignment 
```{r}
attributions<-interpret.predictors(cluster.model)
```

# Extract Motifs in Data
```{r}
parameters.2<-update.parameters(parameters,list(encoder_base="GCNConv",model_save_loc="cluster.model.2.pkl"))
cluster.model.2<-cluster.model.fit(parameters.2, net.list)
plot.diagnostics(cluster.model.2)
summary(cluster.model.2)
```
Motif Visualization:
```{r}
motif.graphs<-extract.motifs(cluster.model.2)
# extract specific motifs
# motif.graphs.2<-extract.motifs(cluster.model.2,node_idx=c(4L,7L,23L,60L,70L))
cl<-extract.clusters(cluster.model.2)
predictor.importance<-build.importance.matrix(motif.graphs,cl,extract.features(cluster.model.2))

vis.motif(motif.graphs,60L,cl,threshold=0.1, weight.scaling.factor = 2., important.node.size=10) 
vis.motif(motif.graphs,60L,cl,threshold=0.2)
vis.motif(motif.graphs,60L,cl,threshold=0.3, weight.scaling.factor = 2., important.node.size=10)
vis.motif(motif.graphs,60L,cl,threshold=0.4, weight.scaling.factor = 2., important.node.size=10)
vis.motif(motif.graphs,60L,cl,threshold=0.5)

vis.motif(motif.graphs,7L,cl,threshold=0.3)
vis.motif(motif.graphs,70L,cl,threshold=0.3)
# More advanced examples
vis.motif(motif.graphs,4L,cl,threshold=0.3, weight.scaling.factor=1.5)
vis.motif(motif.graphs,70L,cl,threshold=0.45, other.idx=c(1L,12L), weight.scaling.factor=1.5, important.node.size=10)
vis.motif(motif.graphs,70L,cl,threshold=0.25, weight.scaling.factor=1.5, other.idx=c(60L, 7L, 4L), centrality.measure="none")
motif<-vis.motif(motif.graphs,23L,cl,threshold=0.35, centrality.measure="strength", floor.size=3, ceil.size=15)
vis.motif(motif.graphs,23L,cl,threshold=0.35, centrality.measure="clusterrank", floor.size=3, ceil.size=15)

```

# Node importance measurements
```{r}
# performance-based
# change in cluster membership or decrease performance model
cl<-extract.clusters(cluster.model)
importance.performance<-plot.node.importance(cluster.model,importance.type = "performance", relate.cluster.meas=T, weight.scaling.factor=2, cl=cl, floor.size = 2., ceil.size=10)

# gradient-based
# sum abs value node features
importance.gradient<-plot.node.importance(cluster.model,importance.type = "gradient", relate.cluster.meas=T, weight.scaling.factor=2, cl=cl)

# attention-based
# strength of layer or aggregated across layers
importance.attention<-plot.node.importance(cluster.model,importance.type = "attention", relate.cluster.meas=T, weight.scaling.factor=2, cl=cl, layers.idx = c(1))

# motif-based, for now just centrality, measure
# what part of total graph does motif occupy * betweeness centrality or average path length
# or how much does removal of  motif effect accuracy
cl<-extract.clusters(cluster.model.2)
importance.motif<-plot.node.importance(cluster.model.2,importance.type = "motif", relate.cluster.meas=T, weight.scaling.factor=2, cl=cl, motif.threshold = 0.3)
```
```{r}
importances<-data.frame(attention=importance.attention,
                       performance=importance.performance,
                       motif=importance.motif,
                       gradient=importance.gradient)
ggplot(importances)+
  geom_jitter(aes(attention,performance))+
  labs(x="Attention Node Importance",y="Performance Node Importance")+
  ggtitle(paste("Comparison of Attention to Performance Node Importances;","SpearmanR =",toString(round(cor(importance.attention,importance.performance,method="spearman"),2))))+
  theme_minimal()

ggplot(importances)+
  geom_jitter(aes(attention,motif))+
  labs(x="Attention Node Importance",y="Motif Node Importance")+
  ggtitle(paste("Comparison of Attention to Motif Node Importances;","SpearmanR =",toString(round(cor(importance.attention,importance.motif,method="spearman"),2))))+
  theme_minimal()

```

# Matching graph embeddings to multivariate normal distribution
```{r}
parameters.3<-update.parameters(parameters,list(ae_type="ARGVA",
                                                K=2L,
                                                lambda_kl=1e-2,
                                                kl_warmup=10L,
                                                lambda_adv=1e-4,
                                                lambda_recon=1.,
                                                lambda_cluster=3.,
                                                epoch_cluster=120L,
                                                n_layers=2L,
                                                model_save_loc="generative.model.pkl"))
embedding.model<-cluster.model.fit(parameters.3, net.list)
z<-extract.embeddings(embedding.model)
cl<-extract.clusters(embedding.model)
lo<-make.layout(z)
G.true<-extract.graphs(embedding.model)$A.true
plot.net(G.true,cl,layout=lo)
```

# Plot diagnostics with added variational KL divergence loss
```{r}
summary(embedding.model)
plot.diagnostics(embedding.model)
```

# Simulate Networks from Variational Graph Auto-Encoder model
```{r}
sim.graphs<-simulate.networks(embedding.model,nsim=30)
cl<-extract.clusters(embedding.model)
for (i in c(1,2,20,30)){
  net<-sim.graphs$networks[[i]]
  embedding<-sim.graphs$embeddings[[i]]
  lo<-make.layout(embedding)
  plot.net(net,cl,layout = lo)
}
```

# Run classification model
```{r}
parameters.4<-update.parameters(parameters,list(ae_type="GAE",
                                                K=2L,
                                                lambda_kl=0,
                                                lambda_recon=0.,
                                                lambda_cluster=0.,
                                                epoch_cluster=120L,
                                                n_layers=2L,
                                                lambda_pred=5.,
                                                prediction_column="office2",
                                                model_save_loc="prediction.model.pkl"))

prediction.model<-classify.model.fit(parameters.4, net.list)
plot.diagnostics(prediction.model)
summary(prediction.model)

z<-extract.embeddings(prediction.model)
y<-apply(extract.prediction(prediction.model),1,function(x) which.max(x))
lo<-make.layout(z)
G.true<-extract.graphs(prediction.model)$A.true
plot.net(G.true,y,layout=lo)
```

# Miscellaneous / Deprecated
# Animate the fitting procedures for the network
```{r}
parameters.4<-update.parameters(parameters,list(animation_save_file="animation.pkl"))
animate.model<-cluster.model.fit(parameters.4, net.list)
animate.plot(animate.model,res=200, delay = 0.04)
```

# Add GNN terms to ERGM model (could attention matrix be used for peer effects?)
```{r}
cl<-extract.clusters(cluster.model)
summary(net.mod0<-ergm.network(net~edges,cluster.model, add.dist = F,simulate=F,pseudo=T))
summary(net.mod1<-ergm.network(net~edges+nodematch("cl",diff=T),cluster.model, add.dist = F,simulate=F,pseudo=T))
summary(net.mod2<-ergm.network(net~edges,cluster.model, distance.metric = "correlation",add.dist = T,simulate=F,pseudo=T))
summary(net.mod3<-ergm.network(net~edges+nodematch("cl",diff=T)+triangle,cluster.model, distance.metric = "euclidean",add.dist = T,simulate=F,pseudo=T))
plot.net(extract.graphs(cluster.model)$A.true,cl)
for(net.mod in list(net.mod0,net.mod1,net.mod2,net.mod3)){
  plot.net(asIgraph(simulate(net.mod)),cl)
}
```

# Comparisons to other R Libraries
# Egocentric extraction
```{r}
sna.net<-asNetwork(net)
ego.nets<-ego.extract(sna.net)
set.seed(42)

ego.net<-graph_from_adjacency_matrix(ego.nets[[23]],weighted=T)
V(ego.net)$color<-V(ego.net)$name=="23"
V(ego.net)$shape<-rep("circle",length(V(ego.net)$color))
V(ego.net)$shape[V(ego.net)$name=="23"]<-"square"
vis.weighted.graph(weight_matrix =ego.nets[[23]],cl=cl,important.nodes=23L,floor.size=6, important.node.size = 10)
plot.net(ego.net)
net.unweighted<-graph_from_adjacency_matrix(net.mat+t(net.mat),weighted=T,mode = "upper")
ego.net<-make_ego_graph(net, order = 1, nodes = 24, mode = c("all"),mindist = 0)[[1]]
degree.distribution(ego.net)

ego.net.mat<-as.matrix(as_adjacency_matrix(ego.net))
rownames(ego.net.mat)<-as.numeric(ego(net, order=1, nodes=24)[[1]])
colnames(ego.net.mat)<-rownames(ego.net.mat)
degree.distribution(graph_from_adjacency_matrix(ego.net.mat+t(ego.net.mat),"upper"))
plot(ego.net)
vis.weighted.graph(ego.net.mat,cl=cl,important.nodes=24,floor.size=6, important.node.size = 10)
print(length(V(ego.net)))
gd<-geodist(ego.net.mat)
sum(!is.infinite(gd$gdist[24,]))
gd$gdist[24,]
gd<-geodist(asNetwork(net.unweighted))
gd$gdist[24,]
motif<-get.motif(motif.graphs,23L)>0.35
motif<-motif+t(motif)
gd<-geodist(motif)
sum(is.infinite(gd$gdist[24,]))
gd$gdist[24,]
net.mat<-as_adjacency_matrix(net)
length(E(net))
length(E(net.unweighted))
length(E(ego.net))
length(V(ego.net))
length(V(graph_from_adjacency_matrix(motif)))
length(E(graph_from_adjacency_matrix(motif+t(motif),weighted=T,mode = "upper")))
geodist(get.motif(motif.graphs,23L)>0.3)$gdist[24,]
```

# ERGM (link prediction; coefficients)
```{r}
summary(mod<-ergm(asNetwork(net)~edges+nodecov("seniority")+nodecov("age")+nodematch("practice")+nodematch("office")))

set.seed(42)
n.sim<-50
Adj<-as_adjacency_matrix(asIgraph(simulate(mod)))
for (i in 1:(n.sim-1)){
  Adj<-Adj+as_adjacency_matrix(asIgraph(simulate(mod)))
}
Adj<-Adj/n.sim
Adj<-as.matrix(Adj)
diag(Adj)<-0.

net.list.2<-net.list
net.list.2$X<-net.list.2$X[,c("seniority","age","practice2","office2","office3")]
net.list.2$A<-(net.list.2$A+t(net.list.2$A))/2
diag(net.list.2$A)<-0
parameters.5<-update.parameters(parameters,list(ae_type="ARGA",
                                                K=3L,
                                                n_hidden=50L,
                                                lambda_kl=0.,
                                                kl_warmup=80L,
                                                val_ratio=0.1,
                                                test_ratio=0.1,
                                                lambda_adv=5.,
                                                lambda_recon=30.,
                                                lambda_cluster=0.,
                                                epoch_cluster=80L,
                                                n_layers=2L,
                                                model_save_loc="link.model.pkl"))
link.model<-link.prediction.model.fit(parameters.5, net.list.2)
plot.diagnostics(link.model)
summary(link.model)

Adj.true<-as.matrix(as_adjacency_matrix(extract.graphs(link.model)$A.true))
diag(Adj.true)<-0
sklearn<-import("sklearn")
set.seed(42)
Adj.gnn<-link.model$results$A
diag(Adj.gnn)<-0.
N<-length(as.vector(Adj.gnn))
idx<-1:N
y_true<-as.vector(Adj.true)
y_pred.gnn<-as.vector(Adj.gnn)
y_pred.ergm<-as.vector(Adj)
set.seed(42)
y_pred.ergm.sim<-as.vector(as.matrix(as_adjacency_matrix(asIgraph(simulate(mod)))))
boot.auc<-function(y.true,y.pred){
  set.seed(42)
  aucs<-c()
  for (i in 1:1000){
    idx.new<-sample(idx,N,replace=T)
    aucs<-c(aucs,sklearn$metrics$roc_auc_score(y.true[idx.new],y.pred[idx.new]))
  }
  return(aucs)
}

aucs.gnn<-boot.auc(y_true,y_pred.gnn)
plot(density(aucs.gnn))

aucs.ergm<-boot.auc(y_true,y_pred.ergm)
plot(density(aucs.ergm))

aucs.sim<-boot.auc(y_true,y_pred.ergm.sim)
plot(density(aucs.sim))

wilcox.test(aucs.ergm,aucs.gnn,alternative="greater")

c(sort(aucs.gnn)[c(25,500,975)],sklearn$metrics$roc_auc_score(y_true,y_pred.gnn))
c(sort(aucs.ergm)[c(25,500,975)],sklearn$metrics$roc_auc_score(y_true,y_pred.ergm))
c(sort(aucs.sim)[c(25,500,975)],sklearn$metrics$roc_auc_score(y_true,y_pred.ergm.sim))


get.max.f1<-function(pred,return_val="objective"){
  m.val<--1
  if (return_val!='objective'){m.val<-m.val*-1}
  return(m.val*optimize(function(x) -sklearn$metrics$f1_score(y_true,pred>x),c(0,1))[[return_val]])
}
get.max.f1(y_pred.gnn)
get.max.f1(y_pred.ergm)
get.max.f1(y_pred.ergm.sim)
plot(degree_distribution(graph_from_adjacency_matrix(Adj.gnn>get.max.f1(y_pred.gnn,"minimum")),mode='all'))
plot(degree_distribution(graph_from_adjacency_matrix(Adj>get.max.f1(y_pred.ergm,"minimum")),mode='all'))
```

# Social Influence (should not do this on binary outcomes)
```{r}
# fit lnam model
X<-data.frame(vertex_attr(net))
geo.dist<-distances(net)
inv.geo.dist<-geo.dist^(-1)
diag(inv.geo.dist)<-0
fit <- lnam(y=V(net)$practice,x=as.matrix(X[,c("seniority","age","gender")]),NULL,inv.geo.dist)

# inspect autoregressive dependence
summary(fit)

# get social influence from fit model
inf<-matrix(0,ncol=fit$df.total,nrow=fit$df.total)
if(!is.null(fit$W1))
   inf<-inf+qr.solve(diag(fit$df.total)-apply(sweep(fit$W1,1,fit$rho1,"*"), c(2,3),sum))
if(!is.null(fit$W2))
   inf<-inf+qr.solve(diag(fit$df.total)-apply(sweep(fit$W2,1,fit$rho2,"*"), c(2,3),sum))
syminf<-abs(inf)+abs(t(inf))
diag(syminf)<-0
infco<-cmdscale(as.dist(max(syminf)-syminf),k=2)
diag(inf)<-NA
stdinf<-inf-mean(inf,na.rm=TRUE)
infsd<-sd(as.vector(stdinf),na.rm=TRUE)
stdinf<-stdinf/infsd
stdinf[is.na(stdinf)]<-0

# plot social influence matrix
vis.weighted.graph(abs(stdinf),weight.scaling.factor = 0.7,cl=X$practice,threshold=1.96)

# 
vis.weighted.graph((attention.matrices[[1]])%*%(attention.matrices[[2]]),cl=extract.clusters(cluster.model))
vis.weighted.graph(attention.matrices[[1]]%*%attention.matrices[[2]],cl=extract.clusters(cluster.model),threshold=0.05)
vis.weighted.graph(attention.matrices[[1]],cl=extract.clusters(cluster.model),threshold=0.1)
vis.weighted.graph(attention.matrices[[2]],cl=extract.clusters(cluster.model),threshold=0.002)


net.list.2<-net.list
net.list.2$X<-net.list.2$X[,c("seniority","age","practice2","gender2")]
net.list.2$A<-(net.list.2$A+t(net.list.2$A))/2
diag(net.list.2$A)<-0
parameters.6<-update.parameters(parameters,list(ae_type="GAE",
                                                K=2L,
                                                lambda_kl=0,
                                                lambda_recon=0.,
                                                lambda_cluster=0.,
                                                epoch_cluster=120L,
                                                n_layers=3L,
                                                lambda_pred=5.,
                                                prediction_column="practice2",
                                                model_save_loc="prediction.model.2.pkl"))

prediction.model<-classify.model.fit(parameters.6, net.list.2)
plot.diagnostics(prediction.model)
summary(prediction.model)
attn.matrices<-visualize.attention(prediction.model,plot=F)
torch<-import("torch")
for (i in 1:4){
  vis.weighted.graph(attn.matrices[[i]],cl=X$practice,threshold=0.05,weight.scaling.factor = 2.5)
}

vis.weighted.graph(attn.matrices[[2]]%*%attn.matrices[[3]],cl=X$practice,threshold=0.06,weight.scaling.factor = 2.5)

vis.weighted.graph(attn.matrices[[1]]%*%attn.matrices[[2]]%*%attn.matrices[[3]]%*%attn.matrices[[4]],cl=X$practice,threshold=0.02,weight.scaling.factor = 0.75)

vis.weighted.graph(abs(stdinf),weight.scaling.factor = 0.7,cl=X$practice,threshold=1.96)
#torch$argmax(prediction.model$results$y,dim=1L)$numpy()
```

# Louvain Modularity / LatentNet Clustering
```{r}
sklearn<-import("sklearn")

# Louvain
cl.louvain<-run.louvain(net)
cl.gnn<-extract.clusters(cluster.model)

sklearn$metrics$normalized_mutual_info_score(cl.gnn,cl.louvain)
plot(cluster.model)

# LatentNet
latent.cluster.fit<-ergm.network(net~rreceiver+rsender+bilinear(d=2,G=3),cluster.model, distance.metric = "correlation",add.dist = F,simulate=F,pseudo=F, use_ergmm = T)
summary(latent.cluster.fit)
plot(latent.cluster.fit)
cl.latent.net<-latent.cluster.fit$mcmc.mle$Z.K
sklearn$metrics$normalized_mutual_info_score(cl.gnn,cl.latent.net)
sklearn$metrics$normalized_mutual_info_score(cl.louvain,cl.latent.net)
lo<-make.layout(latent.cluster.fit$mcmc.mle$Z)
plot.net(net,cl.latent.net,layout=lo)

set.seed(42)
plot.net(net,group=cl.latent.net)
set.seed(42)
plot.net(net,group=cl.gnn)
set.seed(42)
plot.net(net,group=cl.louvain)
```

